import librosa
import numpy as np
import soundfile as sf
import scipy.signal as signal
import pywt
from sklearn.decomposition import FastICA

def high_pass_filter(audio, sr, cutoff=150):
    """L·ªçc High-Pass ƒë·ªÉ lo·∫°i b·ªè nhi·ªÖu t·∫ßn s·ªë th·∫•p."""
    sos = signal.butter(6, cutoff, btype='highpass', fs=sr, output='sos')
    return signal.sosfilt(sos, audio)

def low_pass_filter(audio, sr, cutoff=6000):
    """L·ªçc Low-Pass ƒë·ªÉ gi·ªØ l·∫°i ph·∫ßn gi·ªçng h√°t, lo·∫°i b·ªè nh·∫°c n·ªÅn."""
    sos = signal.butter(6, cutoff, btype='lowpass', fs=sr, output='sos')
    return signal.sosfilt(sos, audio)

def separate_hpss(audio, sr, n_fft=2048, hop_length=512, margin=1.5):
    """T√°ch gi·ªçng h√°t v√† nh·∫°c n·ªÅn b·∫±ng HPSS (c·∫£i thi·ªán)."""
    stft_audio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length)
    harmonic, percussive = librosa.decompose.hpss(stft_audio, margin=margin)
    
    vocal_audio = librosa.istft(harmonic, hop_length=hop_length)
    music_audio = librosa.istft(percussive, hop_length=hop_length)

    return vocal_audio, music_audio

def apply_ica(vocal_audio, music_audio, sr):
    """√Åp d·ª•ng ICA ƒë·ªÉ t·ªëi ∆∞u ph√¢n t√°ch gi·ªçng h√°t v√† nh·∫°c n·ªÅn."""
    X = np.c_[vocal_audio, music_audio]  # Gh√©p t√≠n hi·ªáu th√†nh ma tr·∫≠n ngu·ªìn
    ica = FastICA(n_components=2, max_iter=1000)
    sources = ica.fit_transform(X)  # T√°ch c√°c ngu·ªìn ƒë·ªôc l·∫≠p

    # X√°c ƒë·ªãnh ngu·ªìn n√†o l√† gi·ªçng h√°t b·∫±ng ph√¢n t√≠ch ph·ªï t·∫ßn s·ªë
    def dominant_frequency(signal, sr):
        fft_spectrum = np.abs(np.fft.rfft(signal))
        freqs = np.fft.rfftfreq(len(signal), d=1/sr)
        return np.sum(freqs * fft_spectrum) / np.sum(fft_spectrum)  # Tr·ªçng s·ªë ph·ªï

    freq1 = dominant_frequency(sources[:, 0], sr)
    freq2 = dominant_frequency(sources[:, 1], sr)

    # Gi·ªçng h√°t th∆∞·ªùng c√≥ t·∫ßn s·ªë tr·ªçng t√¢m t·ª´ 300Hz - 4000Hz
    if 300 <= freq1 <= 4000:
        return sources[:, 0], sources[:, 1]  # Vocal - Music
    else:
        return sources[:, 1], sources[:, 0]  # Ho√°n ƒë·ªïi n·∫øu c·∫ßn

def wavelet_denoise(audio, wavelet="db6", level=3):
    """L·ªçc nhi·ªÖu t√≠n hi·ªáu b·∫±ng Wavelet Transform."""
    coeffs = pywt.wavedec(audio, wavelet, level=level)
    threshold = np.median(np.abs(coeffs[-level])) / 0.6745  # T√≠nh ng∆∞·ª°ng
    coeffs_denoised = [pywt.threshold(c, threshold, mode="soft") for c in coeffs]
    return pywt.waverec(coeffs_denoised, wavelet)

def normalize_audio(audio):
    """Chu·∫©n h√≥a √¢m l∆∞·ª£ng."""
    return audio / (np.max(np.abs(audio)) + 1e-7)

def process_audio(input_path, output_vocal, output_music):
    """T√°ch gi·ªçng h√°t v√† nh·∫°c n·ªÅn k·∫øt h·ª£p HPSS + ICA + Wavelet Transform."""
    audio, sr = librosa.load(input_path, sr=None, mono=True)

    # B∆∞·ªõc 1: HPSS t√°ch s∆° b·ªô
    vocal, music = separate_hpss(audio, sr)

    # üî• S·ª≠a l·ªói: Truy·ªÅn th√™m `sr` v√†o `apply_ica()`
    vocal_ica, music_ica = apply_ica(vocal, music, sr)

    # B∆∞·ªõc 3: L·ªçc t·∫°p √¢m b·∫±ng Wavelet Transform
    vocal_clean = wavelet_denoise(vocal_ica)
    music_clean = wavelet_denoise(music_ica)

    # B∆∞·ªõc 4: L·ªçc High-Pass v√† Low-Pass
    vocal_clean = high_pass_filter(vocal_clean, sr)
    vocal_clean = low_pass_filter(vocal_clean, sr)

    # B∆∞·ªõc 5: Chu·∫©n h√≥a t√≠n hi·ªáu
    vocal_clean = normalize_audio(vocal_clean)
    music_clean = normalize_audio(music_clean)

    # L∆∞u file ƒë·∫ßu ra
    sf.write(output_vocal, vocal_clean, sr)
    sf.write(output_music, music_clean, sr)

    return output_vocal, output_music
